{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8th_dacon_astronomy_code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM8h3A0puSwguQGs2OGuTun",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PythonMachineLearningInKorea/SanghoPark/blob/master/8th_dacon_astronomy_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMNug7k9xY9r",
        "colab_type": "code",
        "outputId": "6a2cb992-8f3c-4ad6-87e2-05002ff79c0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import math \n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n. Also, this code is from This code is from https://dacon.io/competitions/official/235573/codeshare/692
It is not mine.",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rNQEKxgxgDq",
        "colab_type": "code",
        "outputId": "8f54da31-c1b5-4643-f79f-97bc0f828c63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/datrain.csv', index_col=0)\n",
        "test = pd.read_csv('/content/drive/My Drive/datest.csv', index_col=0)\n",
        "sample_submission = pd.read_csv('/content/drive/My Drive/sample_submission.csv', index_col=0)\n",
        "# index_col specifies a certain column as the row index.\n",
        "sample_submission.describe()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STAR_WHITE_DWARF</th>\n",
              "      <th>STAR_CATY_VAR</th>\n",
              "      <th>STAR_BROWN_DWARF</th>\n",
              "      <th>SERENDIPITY_RED</th>\n",
              "      <th>REDDEN_STD</th>\n",
              "      <th>STAR_BHB</th>\n",
              "      <th>GALAXY</th>\n",
              "      <th>SERENDIPITY_DISTANT</th>\n",
              "      <th>QSO</th>\n",
              "      <th>SKY</th>\n",
              "      <th>STAR_RED_DWARF</th>\n",
              "      <th>ROSAT_D</th>\n",
              "      <th>STAR_PN</th>\n",
              "      <th>SERENDIPITY_FIRST</th>\n",
              "      <th>STAR_CARBON</th>\n",
              "      <th>SPECTROPHOTO_STD</th>\n",
              "      <th>STAR_SUB_DWARF</th>\n",
              "      <th>SERENDIPITY_MANUAL</th>\n",
              "      <th>SERENDIPITY_BLUE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10009.0</td>\n",
              "      <td>10009.0</td>\n",
              "      <td>10009.0</td>\n",
              "      <td>10009.0</td>\n",
              "      <td>10009.0</td>\n",
              "      <td>10009.0</td>\n",
              "      <td>10009.0</td>\n",
              "      <td>10009.0</td>\n",
              "      <td>10009.0</td>\n",
              "      <td>10009.0</td>\n",
              "      <td>10009.0</td>\n",
              "      <td>10009.0</td>\n",
              "      <td>10009.0</td>\n",
              "      <td>10009.0</td>\n",
              "      <td>10009.0</td>\n",
              "      <td>10009.0</td>\n",
              "      <td>10009.0</td>\n",
              "      <td>10009.0</td>\n",
              "      <td>10009.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       STAR_WHITE_DWARF  STAR_CATY_VAR  ...  SERENDIPITY_MANUAL  SERENDIPITY_BLUE\n",
              "count           10009.0        10009.0  ...             10009.0           10009.0\n",
              "mean                0.0            0.0  ...                 0.0               0.0\n",
              "std                 0.0            0.0  ...                 0.0               0.0\n",
              "min                 0.0            0.0  ...                 0.0               0.0\n",
              "25%                 0.0            0.0  ...                 0.0               0.0\n",
              "50%                 0.0            0.0  ...                 0.0               0.0\n",
              "75%                 0.0            0.0  ...                 0.0               0.0\n",
              "max                 0.0            0.0  ...                 0.0               0.0\n",
              "\n",
              "[8 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEZFLnWLPxEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gives numbers to columns\n",
        "\n",
        "column_number = {}\n",
        "for i, column in enumerate(sample_submission.columns):\n",
        "    column_number[column] = i\n",
        "    \n",
        "def to_number(x, dic):\n",
        "    return dic[x]\n",
        "\n",
        "train['type_num'] = train['type'].apply(lambda x: to_number(x, column_number))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2T2Ru0Yc7LB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make Fiber tpye\n",
        "fiber = []\n",
        "label_dict = {}\n",
        "# Set eliminates duplicated data. Also, it cannot be sliced. Set is undordered.\n",
        "for i in list(set(train['fiberID'])):\n",
        "    train2 = train[train['fiberID']==i]\n",
        "    # test2 = test[test['fiberID']==i]\n",
        " \n",
        "    # idx2 = test2.index\n",
        " \n",
        "    # train2 is the list(set(train['fiberID']))\n",
        "\n",
        "    idx1 = train2.index\n",
        "    #print(set(train.loc[idx1]['type_num']))\n",
        "    if tuple(set(train.loc[idx1]['type_num'])) not in fiber:\n",
        "    #tuple is no changeable\n",
        "        fiber.append(tuple(set(train.loc[idx1]['type_num'])))\n",
        "    #튜플 집합을 만들어서 fiber 안에 넣어준다. \n",
        "    label_dict[i] = list(set(train.loc[idx1]['type_num']))\n",
        "    #label_dict 안에는 리스트 집합을 만들어 넣어준다.\n",
        "    \n",
        "fiber_type = {}\n",
        "for k in range(len(fiber)):\n",
        "    fiber_type[fiber[k]] = k\n",
        "    #위에서 만들어준 fiber의 튜플 집합을 fiber_type에 넣어준다.\n",
        "fiber_dict = {}  \n",
        "for j in list(set(train['fiberID'])):\n",
        "    train2 = train[train['fiberID']==j]\n",
        "    #test2 = test[test['fiberID']==i]\n",
        "    idx1 = train2.index\n",
        "    \n",
        "    #print(set(train.loc[idx1]['type_num']))\n",
        "    fiber_dict[j] = fiber_type[tuple(set(train.loc[idx1]['type_num']))]\n",
        "\n",
        "    #fiberID 별로 fiber_dict에 저장\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oaf4qA_khDJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ntrain = train.shape[0]\n",
        "ntest = test.shape[0]\n",
        "all_data = train.append(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkLY1PvqraGT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "b08eb71f-5b7e-4b0e-8364-9b4c23c3a054"
      },
      "source": [
        "all_data['fiberType']"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "0          1\n",
              "1         34\n",
              "2          5\n",
              "3         34\n",
              "4          1\n",
              "          ..\n",
              "209995     5\n",
              "209996     5\n",
              "209997    34\n",
              "209998    34\n",
              "209999     0\n",
              "Name: fiberType, Length: 210000, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht35IwkTnCt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ????\n",
        "\n",
        "all_data['fiberType'] = all_data['fiberID']\n",
        "Fill_Type = lambda x: fiber_dict[x]\n",
        "all_data['fiberType'] = all_data['fiberType'].apply(Fill_Type)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYYACCtoSJWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 변수 생성 및 파생변수 만들기\n",
        "psfMags = ['psfMag_u','psfMag_g','psfMag_r','psfMag_i','psfMag_z']\n",
        "fiberMags = ['fiberMag_u','fiberMag_g','fiberMag_r','fiberMag_i','fiberMag_z']\n",
        "petroMags = ['petroMag_u','petroMag_g','petroMag_r','petroMag_i','petroMag_z']\n",
        "modelMags = ['modelMag_u','modelMag_g','modelMag_r','modelMag_i','modelMag_z']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RDtUmlrxzPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "u_values = ['psfMag_u','fiberMag_u','petroMag_u','modelMag_u']\n",
        "g_values = ['psfMag_g','fiberMag_g','petroMag_g','modelMag_g']\n",
        "r_values = ['psfMag_r','fiberMag_r','petroMag_r','modelMag_r']\n",
        "i_values = ['psfMag_i','fiberMag_i','petroMag_i','modelMag_i']\n",
        "z_values = ['psfMag_z','fiberMag_z','petroMag_z','modelMag_z']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HUTnXijStSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "u_r = ['psfMag_u-r', 'fiberMag_u-r','petroMag_u-r','modelMag_u-r']\n",
        "u_g = ['psfMag_u-g','fiberMag_u-g',  'petroMag_u-g','modelMag_u-g']\n",
        "g_r = ['psfMag_g-r', 'fiberMag_g-r',  'petroMag_g-r', 'modelMag_g-r']      \n",
        "g_z = ['psfMag_g-z','fiberMag_g-z', 'petroMag_g-z','modelMag_g-z'] \n",
        "g_i = ['psfMag_g-i','fiberMag_g-i','petroMag_g-i', 'modelMag_g-i']\n",
        "\n",
        "u_i = ['psfMag_u-i','fiberMag_u-i','petroMag_u-i', 'modelMag_u-i']\n",
        "u_z = ['psfMag_u-z','fiberMag_u-z','petroMag_u-z', 'modelMag_u-z']\n",
        "r_i = ['psfMag_r-i','fiberMag_r-i','petroMag_r-i', 'modelMag_r-i']\n",
        "r_z = ['psfMag_r-z','fiberMag_r-z','petroMag_r-z', 'modelMag_r-z']\n",
        "i_z = ['psfMag_i-z','fiberMag_i-z','petroMag_i-z', 'modelMag_i-z']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqwx0378yNRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sumur = ['psfMag_u+r', 'fiberMag_u+r','petroMag_u+r','modelMag_u+r']\n",
        "sumug = ['psfMag_u+g','fiberMag_u+g',  'petroMag_u+g','modelMag_u+g']\n",
        "sumgr = ['psfMag_g+r', 'fiberMag_g+r',  'petroMag_g+r', 'modelMag_g+r']      \n",
        "sumgz = ['psfMag_g+z','fiberMag_g+z', 'petroMag_g+z','modelMag_g+z'] \n",
        "sumgi = ['psfMag_g+i','fiberMag_g+i','petroMag_g+i', 'modelMag_g+i']\n",
        "\n",
        "sumui = ['psfMag_u+i','fiberMag_u+i','petroMag_u+i', 'modelMag_u+i']\n",
        "sumuz = ['psfMag_u+z','fiberMag_u+z','petroMag_u+z', 'modelMag_u+z']\n",
        "sumri = ['psfMag_r+i','fiberMag_r+i','petroMag_r+i', 'modelMag_r+i']\n",
        "sumrz = ['psfMag_r+z','fiberMag_r+z','petroMag_r+z', 'modelMag_r+z']\n",
        "sumiz = ['psfMag_i+z','fiberMag_i+z','petroMag_i+z', 'modelMag_i+z']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfiCxSKLuG7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols = all_data.columns.drop(['type','type_num','fiberType','fiberID'])\n",
        "#drop the columns 'type','type_num','fiberType','fiberID'\n",
        "pca = PCA(n_components = 2)\n",
        "# PCA n_components 2\n",
        "x = all_data[cols].values\n",
        "principalComponents = pca.fit_transform(x)\n",
        "principalDf = pd.DataFrame(data = principalComponents\n",
        "             , columns = ['all_pca1','all_pca2'])\n",
        "# PCA two columns \n",
        "all_data = pd.concat([all_data,principalDf],axis =1)\n",
        "# All data + PCA components"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoIELlsSgGil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(4):\n",
        "    all_data[str(u_values[i])+'-'+'r'] = all_data[u_values[i]]-all_data[r_values[i]]\n",
        "    all_data[str(u_values[i])+'-'+'g'] = all_data[u_values[i]]-all_data[g_values[i]]\n",
        "    all_data[str(g_values[i])+'-'+'r'] = all_data[g_values[i]]-all_data[r_values[i]]\n",
        "    all_data[str(g_values[i])+'-'+'z'] = all_data[g_values[i]]-all_data[z_values[i]]\n",
        "    all_data[str(g_values[i])+'-'+'i'] = all_data[g_values[i]]-all_data[i_values[i]]\n",
        "    \n",
        "    all_data[str(u_values[i])+'-'+'i'] = all_data[u_values[i]]-all_data[i_values[i]]\n",
        "    all_data[str(u_values[i])+'-'+'z'] = all_data[u_values[i]]-all_data[z_values[i]]\n",
        "    all_data[str(r_values[i])+'-'+'z'] = all_data[r_values[i]]-all_data[z_values[i]]\n",
        "    all_data[str(r_values[i])+'-'+'i'] = all_data[r_values[i]]-all_data[i_values[i]]\n",
        "    all_data[str(i_values[i])+'-'+'z'] = all_data[i_values[i]]-all_data[z_values[i]]\n",
        "        \n",
        "        \n",
        "        \n",
        "    all_data[str(u_values[i])+'+'+'r'] = all_data[u_values[i]]+all_data[r_values[i]]\n",
        "    all_data[str(u_values[i])+'+'+'g'] = all_data[u_values[i]]+all_data[g_values[i]]\n",
        "    all_data[str(g_values[i])+'+'+'r'] = all_data[g_values[i]]+all_data[r_values[i]]\n",
        "    all_data[str(g_values[i])+'+'+'z'] = all_data[g_values[i]]+all_data[z_values[i]]\n",
        "    all_data[str(g_values[i])+'+'+'i'] = all_data[g_values[i]]+all_data[i_values[i]]\n",
        "    \n",
        "    all_data[str(u_values[i])+'+'+'i'] = all_data[u_values[i]]+all_data[i_values[i]]\n",
        "    all_data[str(u_values[i])+'+'+'z'] = all_data[u_values[i]]+all_data[z_values[i]]\n",
        "    all_data[str(r_values[i])+'+'+'z'] = all_data[r_values[i]]+all_data[z_values[i]]\n",
        "    all_data[str(r_values[i])+'+'+'i'] = all_data[r_values[i]]+all_data[i_values[i]]\n",
        "    all_data[str(i_values[i])+'+'+'z'] = all_data[i_values[i]]+all_data[z_values[i]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS76Sdx_gZub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_groups = [psfMags,fiberMags,petroMags,modelMags,u_values,g_values,r_values,i_values,z_values,u_r,u_g,g_r,g_z,g_i,u_i,u_z,r_i,r_z,i_z,sumur, sumug, sumgr,  sumgz, sumgi, sumui, sumuz, sumri ,sumrz ,sumiz]\n",
        "group_names = ['psf','fiber','petro','model','u','g','r','i','z','u-r','u-g','g-r','g-z','g-i','u-i','u-z','r-i','r-z','i-z','sumur', 'sumug', 'sumgr',  'sumgz', 'sumgi', 'sumui', 'sumuz', 'sumri' ,'sumrz' ,'sumiz']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDemA35NxAod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mean and standard pca three components.\n",
        "pca = PCA(n_components = 3)\n",
        "\n",
        "for i in range(len(val_groups)):\n",
        "    \n",
        "    all_data[str(group_names[i])+'_mean'] = all_data[val_groups[i]].mean(axis =1)\n",
        "    all_data[str(group_names[i])+'_std'] = all_data[val_groups[i]].std(axis =1)\n",
        "\n",
        "    x = all_data[val_groups[i]].values\n",
        "    principalComponents = pca.fit_transform(x)\n",
        "    principalDf = pd.DataFrame(data = principalComponents\n",
        "             , columns = [str(group_names[i]) + '_pca1', str(group_names[i]) + '_pca2',str(group_names[i]) + '_pca3'])\n",
        "    #print(group_names[i])\n",
        "    #print('explained variance ratio :', pca.explained_variance_ratio_)\n",
        "\n",
        "    all_data = pd.concat([all_data,principalDf],axis =1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTf8begTRcGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Rotation with respect to the center!\n",
        "def RotateXY(x,y,xc=0,yc=0,angle=0,units=\"DEGREES\"):  \n",
        "    \"\"\"Rotate an xy cooordinate about a specified origin  \n",
        "  \n",
        "    x,y      xy coordinates  \n",
        "    xc,yc   center of rotation  \n",
        "    angle   angle  \n",
        "    units    \"DEGREES\" (default) or \"RADIANS\"  \n",
        "    \"\"\"  \n",
        "    import math  \n",
        "    x = x - xc  \n",
        "    y = y - yc  \n",
        "    if units == \"DEGREES\":  \n",
        "        angle = math.radians(angle)  \n",
        "    xr = (x * math.cos(angle)) - (y * math.sin(angle)) + xc  \n",
        "    yr = (x * math.sin(angle)) + (y * math.cos(angle)) + yc  \n",
        "    return xr, yr  \n",
        "    # We need the angle as a radian unit. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqDVYe9sxAqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "for i in range(4):\n",
        "    start = datetime.datetime.now()\n",
        "    u_g_1 = []\n",
        "    u_g_2 = []\n",
        "    g_r_1 = []\n",
        "    g_r_2 = []\n",
        "    g_z_1 = []\n",
        "    g_z_2 = []\n",
        "    g_i_1 = []\n",
        "    g_i_2 = []\n",
        "    r_i_1 = []\n",
        "    r_i_2 = []\n",
        "        \n",
        "    for k in range(len(all_data)):\n",
        "        \n",
        "        Rotate = RotateXY(all_data[str(u_values[i])+'-'+'g'].loc[k],all_data[str(r_values[i])].loc[k],xc=0,yc=0,angle=45,units=\"DEGREES\")\n",
        "        u_g_1.append(Rotate[0])\n",
        "        u_g_2.append(Rotate[1])\n",
        "        \n",
        "        Rotate = RotateXY(all_data[str(g_values[i])+'-'+'r'].loc[k],all_data[str(r_values[i])].loc[k],xc=0,yc=0,angle=45,units=\"DEGREES\")\n",
        "        g_r_1.append(Rotate[0])\n",
        "        g_r_2.append(Rotate[1])\n",
        "        \n",
        "        \n",
        "        Rotate = RotateXY(all_data[str(g_values[i])+'-'+'z'].loc[k],all_data[str(r_values[i])].loc[k],xc=0,yc=0,angle=45,units=\"DEGREES\")\n",
        "        g_z_1.append(Rotate[0])\n",
        "        g_z_2.append(Rotate[1])\n",
        "        \n",
        "        Rotate = RotateXY(all_data[str(g_values[i])+'-'+'i'].loc[k],all_data[str(r_values[i])].loc[k],xc=0,yc=0,angle=45,units=\"DEGREES\")\n",
        "        g_i_1.append(Rotate[0])\n",
        "        g_i_2.append(Rotate[1])\n",
        "        \n",
        "        Rotate = RotateXY(all_data[str(r_values[i])+'-'+'i'] .loc[k],all_data[str(r_values[i])].loc[k],xc=0,yc=0,angle=45,units=\"DEGREES\")\n",
        "        r_i_1.append(Rotate[0])\n",
        "        r_i_2.append(Rotate[1])   \n",
        "        \n",
        "    ug1= pd.DataFrame(data = u_g_1\n",
        "             , columns = [str(u_values[i])+'-'+'g'+'r451'])\n",
        "    ug2= pd.DataFrame(data = u_g_2\n",
        "             , columns = [str(u_values[i])+'-'+'g'+'r452'])\n",
        "       \n",
        "    gr1= pd.DataFrame(data = g_r_1\n",
        "             , columns = [str(g_values[i])+'-'+'r'+'r451'])\n",
        "    gr2= pd.DataFrame(data = g_r_2\n",
        "             , columns = [str(g_values[i])+'-'+'r'+'r452'])\n",
        "        \n",
        "    gz1= pd.DataFrame(data = g_z_1\n",
        "             , columns = [str(g_values[i])+'-'+'z'+'r451'])\n",
        "    gz2= pd.DataFrame(data = g_z_2\n",
        "             , columns = [str(g_values[i])+'-'+'z'+'r452'])\n",
        "        \n",
        "        \n",
        "    gi1= pd.DataFrame(data = g_i_1\n",
        "             , columns = [str(g_values[i])+'-'+'i'+'r451'])\n",
        "    gi2= pd.DataFrame(data = g_i_2\n",
        "             , columns = [str(g_values[i])+'-'+'i'+'r452'])   \n",
        "    \n",
        "    ri1= pd.DataFrame(data = r_i_1\n",
        "             , columns = [str(r_values[i])+'-'+'i'+'r451'])\n",
        "    ri2= pd.DataFrame(data = r_i_2\n",
        "             , columns = [str(r_values[i])+'-'+'i'+'r452'])\n",
        "             \n",
        "    \n",
        "    all_data = pd.concat([all_data,ug1,ug2,gr1,gr2,gz1,gz2,gi1,gi1,ri1,ri2],axis =1)\n",
        "    runtime = datetime.datetime.now() - start\n",
        "    break    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIua1unKPWaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ntrain 할당\n",
        "train= all_data[:ntrain]\n",
        "test= all_data[ntrain:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyxOvhQ_TCDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# N# QSO 34 할당\n",
        "\n",
        "y = train['type_num']\n",
        "train = train.drop(columns=['type','type_num'], axis=1)\n",
        "train1 = train[train['fiberType'] != 34]\n",
        "train2 = train[train['fiberType'] == 34]\n",
        "train1_idx = train1.index \n",
        "train2_idx = train2.index\n",
        "y1 = y.loc[train1_idx]\n",
        "\n",
        "test = test.drop(['type','type_num'], axis=1)\n",
        "test1 = test[test['fiberType'] != 34]\n",
        "test2 = test[test['fiberType'] == 34]\n",
        "test1_idx = test1.index\n",
        "test2_idx = test2.index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1o6poeYPFmW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "333677d7-88da-4249-f86c-3813534a3b60"
      },
      "source": [
        "# Hyperparameter tuning : Bayesian optimization\n",
        "# 20-fold cross validation\n",
        "# LGBM fitting\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "kfold = 20\n",
        "kf = StratifiedKFold(n_splits=kfold, shuffle=True, random_state = 42)\n",
        "preds =[]\n",
        "for train_index, test_index in kf.split(train1, y1):\n",
        "    x_train, x_val = train1.iloc[train_index], train1.iloc[test_index]\n",
        "    y_train, y_val = y1.iloc[train_index], y1.iloc[test_index]\n",
        "    \n",
        "    clf = lgb.LGBMClassifier(n_estimators = 10000, max_depth=10, learning_rate=0.009, objective='multiclass',num_class = 19\n",
        "                             ,num_leaves = 1024,random_state=42,metric = 'multi_logloss',boost_from_average = False,\n",
        "                            feature_fraction =0.21815809919426804,bagging_fraction = 0.8055711236002633,lambda_l1 = 0.0029896841778409566,\n",
        "                             lambda_l2 = 0.06905300928232105,min_split_gain = 0.05931126989247223,min_child_weight = 10)\n",
        "    clf.fit(x_train, y_train, eval_set=[(x_train, y_train), (x_val, y_val)],\n",
        "            early_stopping_rounds=50, verbose=100)\n",
        "    \n",
        "    \n",
        "    \n",
        "    # fiberID ==34 인 test_set에 QSO =1로 채워넣음\n",
        "    ps = pd.DataFrame(data=clf.predict_proba(test), index=test.index)\n",
        "    sam = sample_submission.copy()\n",
        "    sam.loc[test1_idx] =ps.loc[test1_idx]\n",
        "    sam.loc[test2_idx] = 0\n",
        "    sam.loc[test2_idx,'QSO'] = 1\n",
        "    \n",
        "\n",
        "    preds.append(sam)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds.\n",
            "[100]\ttraining's multi_logloss: 1.05226\tvalid_1's multi_logloss: 1.08366\n",
            "[200]\ttraining's multi_logloss: 0.612936\tvalid_1's multi_logloss: 0.663059\n",
            "[300]\ttraining's multi_logloss: 0.431436\tvalid_1's multi_logloss: 0.496249\n",
            "[400]\ttraining's multi_logloss: 0.346715\tvalid_1's multi_logloss: 0.423345\n",
            "[500]\ttraining's multi_logloss: 0.302327\tvalid_1's multi_logloss: 0.389071\n",
            "[600]\ttraining's multi_logloss: 0.275613\tvalid_1's multi_logloss: 0.371646\n",
            "[700]\ttraining's multi_logloss: 0.257378\tvalid_1's multi_logloss: 0.361985\n",
            "[800]\ttraining's multi_logloss: 0.243617\tvalid_1's multi_logloss: 0.356451\n",
            "[900]\ttraining's multi_logloss: 0.232151\tvalid_1's multi_logloss: 0.353058\n",
            "[1000]\ttraining's multi_logloss: 0.222976\tvalid_1's multi_logloss: 0.350947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0-IAMBaTSLx",
        "colab_type": "code",
        "outputId": "924c5908-4cc1-42e4-bc47-ae7db42c167d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# 위에서 구한 20번의 예측값을 더해서 나눠줌.\n",
        "pred = sum(preds)/20\n",
        "pred.index = sample_submission.index\n",
        "pred.columns = sample_submission.columns\n",
        "pred.to_csv('LGBM_20_Final.csv', index=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_GzKv9EEgjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
